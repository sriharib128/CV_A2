{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'adam'}
Training set has 60000 instances
Validation set has 10000 instances
EPOCH 1:
1000th batch => 23.97429649233818
2000th batch => 23.275395567417146
3000th batch => 23.138217356204986
4000th batch => 23.114233906269074
5000th batch => 23.099473893642426
6000th batch => 23.08377410173416
7000th batch => 23.067642319202424
LOSS train 23.067642319202424 valid 0.28894505922794345 ACC 0.1135
EPOCH 2:
1000th batch => 23.065022308826446
2000th batch => 23.068981878757477
3000th batch => 23.054460854530333
4000th batch => 23.052577772140502
5000th batch => 23.046558594703676
6000th batch => 23.04300194501877
7000th batch => 23.04064549446106
LOSS train 23.04064549446106 valid 0.2876890215873718 ACC 0.1028
EPOCH 3:
1000th batch => 23.031053729057312
2000th batch => 23.043004298210143
3000th batch => 23.031435487270354
4000th batch => 23.03174451828003
5000th batch => 23.03488732814789
6000th batch => 23.026367523670196
7000th batch => 23.03998293161392
LOSS train 23.03998293161392 valid 0.287713766336441 ACC 0.1135
EPOCH 4:
1000th batch => 23.027424533367157
2000th batch => 23.03730814933777
3000th batch => 23.02237199783325
4000th batch => 23.028768215179444
5000th batch => 23.02697909832001
6000th batch => 23.03434068441391
7000th batch => 23.029452970027922
LOSS train 23.029452970027922 valid 0.2877727152585983 ACC 0.1135
EPOCH 5:
1000th batch => 23.028598630428313
2000th batch => 23.024999351501464
3000th batch => 23.023567776679993
4000th batch => 23.03755440711975
5000th batch => 23.02990929365158
6000th batch => 23.02352565765381
7000th batch => 23.040244839191438
LOSS train 23.040244839191438 valid 0.2876365729093552 ACC 0.1135