{'learning_rate': 0.001, 'batch_size': 64, 'epoch': 10, 'optimizer': 'adam'}
Training set has 60000 instances
Validation set has 10000 instances
EPOCH 1:
100th batch => 1.0806842792034148
200th batch => 0.278742106705904
300th batch => 0.18545835487544537
400th batch => 0.14566997803747653
500th batch => 0.13438145775347948
600th batch => 0.12050811596214771
700th batch => 0.10242413160391152
800th batch => 0.09857013694010675
900th batch => 0.07522635676898062
LOSS train 0.07522635676898062 valid 0.0011488795249490068 ACC 0.9773
saved model to ./models/model_20240307_005452_0
EPOCH 2:
100th batch => 0.07315306286327541
200th batch => 0.0692412838852033
300th batch => 0.07584246435202659
400th batch => 0.06203115314245224
500th batch => 0.05894677390344441
600th batch => 0.06735840604756958
700th batch => 0.06499053363222629
800th batch => 0.05043961589224637
900th batch => 0.05441587164299563
LOSS train 0.05441587164299563 valid 0.0006031600922862708 ACC 0.9875
saved model to ./models/model_20240307_005452_1
EPOCH 3:
100th batch => 0.04953925197711215
200th batch => 0.04277902920497581
300th batch => 0.047060423730872575
400th batch => 0.050112640890292826
500th batch => 0.04921356723061763
600th batch => 0.04804431633092463
700th batch => 0.04559210575185716
800th batch => 0.045744238218758254
900th batch => 0.04957385607762262
LOSS train 0.04957385607762262 valid 0.0006373461486466113 ACC 0.9867
EPOCH 4:
100th batch => 0.041501562644261865
200th batch => 0.035342449942836536
300th batch => 0.040666455181781205
400th batch => 0.026963507924228906
500th batch => 0.038618263983516955
600th batch => 0.03658815311617218
700th batch => 0.04200099469991983
800th batch => 0.04037315160734579
900th batch => 0.04039193350588903
LOSS train 0.04039193350588903 valid 0.000556967630636791 ACC 0.9891
saved model to ./models/model_20240307_005452_3
EPOCH 5:
100th batch => 0.029779715249314904
200th batch => 0.02958809327916242
300th batch => 0.03289693955070106
400th batch => 0.029721929390216246
500th batch => 0.031577791229356084
600th batch => 0.03326537270564586
700th batch => 0.026227957928786055
800th batch => 0.029052968479227274
900th batch => 0.041706203952198845
LOSS train 0.041706203952198845 valid 0.0005829974255015259 ACC 0.9881
EPOCH 6:
100th batch => 0.02394347518318682
200th batch => 0.025245543562923557
300th batch => 0.025452126353629864
400th batch => 0.027232928211742547
500th batch => 0.025104002834996208
600th batch => 0.026831148330238648
700th batch => 0.022383243995718657
800th batch => 0.03188643878791481
900th batch => 0.030003490957606117
LOSS train 0.030003490957606117 valid 0.0005089329073649423 ACC 0.9902
saved model to ./models/model_20240307_005452_5
EPOCH 7:
100th batch => 0.0146178188174963
200th batch => 0.02285477012526826
300th batch => 0.01780804051537416
400th batch => 0.02344394206185825
500th batch => 0.023272965565847698
600th batch => 0.019978840225667226
700th batch => 0.0243521542972303
800th batch => 0.02616809210710926
900th batch => 0.024292778473463842
LOSS train 0.024292778473463842 valid 0.0006769239096813863 ACC 0.9859
EPOCH 8:
100th batch => 0.014285356395703275
200th batch => 0.016153448617696995
300th batch => 0.01768790515823639
400th batch => 0.021795592312992086
500th batch => 0.026784162430558353
600th batch => 0.017895941608585417
700th batch => 0.0224620886874618
800th batch => 0.018434233612642858
900th batch => 0.02508223578595789
LOSS train 0.02508223578595789 valid 0.0006178392633700242 ACC 0.9888
EPOCH 9:
100th batch => 0.011523913509809063
200th batch => 0.01816022731254634
300th batch => 0.018368499268835877
400th batch => 0.012892301012179815
500th batch => 0.01815614751103567
600th batch => 0.020386460278823505
700th batch => 0.0169969653392036
800th batch => 0.020206842198967935
900th batch => 0.01937909243395552
LOSS train 0.01937909243395552 valid 0.0005488996852256605 ACC 0.9907
EPOCH 10:
100th batch => 0.011555877961509396
200th batch => 0.017742109104437985
300th batch => 0.010086576569738099
400th batch => 0.013399425078750938
500th batch => 0.01648278219392523
600th batch => 0.019791832459468424
700th batch => 0.020497193938936106
800th batch => 0.015867773562349613
900th batch => 0.018336129262315808
LOSS train 0.018336129262315808 valid 0.0005751876987380456 ACC 0.9906