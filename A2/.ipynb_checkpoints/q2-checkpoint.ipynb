{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e384797e-5ee5-4b5a-8046-8b5989ef5614",
   "metadata": {},
   "source": [
    "# Q2 CNNs and Transformers [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57245f22-3482-4513-9519-d59926e83ead",
   "metadata": {},
   "source": [
    "- Srihari Bandarupalli\n",
    "- 2021112006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2cb97a-4691-4cef-95f6-488a09921997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "# import multiprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1c3d9-2a43-4bed-8e2f-267a7aa1fb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d05a0e-bac7-440b-9669-fbbd99bc51ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cpu', '2.2.0', 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device,torch.__version__,torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501ce963-e54a-40a9-8285-3994b2a41dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ac7902-dfc7-4d8e-9b1a-d6f792c4e43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccd668-db0f-4f26-93dd-1915988b75df",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d02883-dabe-4deb-af92-ab216acf1297",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f09aa70-013a-4309-b436-9845c627c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "def data_get_load(batch_size=64):\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "    \n",
    "    # Create datasets for training & validation, download if necessary\n",
    "    training_set = datasets.MNIST('./data', train=True, transform=transform, download=True)\n",
    "    validation_set = datasets.MNIST('./data', train=False, transform=transform, download=True)\n",
    "    \n",
    "    # Create data loaders for our datasets; shuffle for training, not for validation\n",
    "    training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Report split sizes\n",
    "    print('Training set has {} instances'.format(len(training_set)))\n",
    "    print('Validation set has {} instances'.format(len(validation_set)))\n",
    "\n",
    "    return training_loader,validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249586ab-eddb-4b82-9b4d-cbb0c01fdecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n",
      "0  4  6  2  3  7  9  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "training_loader,validation_loader = data_get_load(8)\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(str(labels[j].numpy()) for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd631d0-62aa-47a2-8cd2-0d24ca9d25a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ff4c509-7280-4f46-b85f-6eeb3447a13d",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e82946a1-d836-4eaf-a60b-1f44197f75fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eefac2e-0f44-4a98-9015-dbe78b8ab9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff719b28-9097-4abf-9679-72962d42598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4df74-f3d2-48f6-9ab4-dcc003fd15fc",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c780668f-daac-4ade-8c0c-74afa3563c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train One epoch\n",
    "\n",
    "def train_one_epoch(model,train_loader,loss_fn,optimizer,device,epoch_index,tb_writer,wandb=None,write = True):\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    running_loss =0\n",
    "    last_loss = 0\n",
    "    losses=[]\n",
    "    for i,data in enumerate(training_loader):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()        \n",
    "        outputs=model(inputs)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if wandb != None:\n",
    "            wandb.log({\"train_loss\": loss.item()})\n",
    "        running_loss +=loss.item()\n",
    "        losses.append(loss.item())\n",
    "        if i%1000 == 999:\n",
    "            last_loss = running_loss/100\n",
    "            print(f\"{i+1}th batch => {last_loss}\")\n",
    "            if(write):\n",
    "                tb_x = epoch_index * len(training_loader)\n",
    "                tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "    if last_loss==0:\n",
    "        return np.mean(np.array(losses))\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d84144d-e92b-43b1-8256-b1f146edf00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one epoch\n",
    "def test_one_epoch(model,test_loader,loss_fn,device,wandb=None):\n",
    "\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_loss =0\n",
    "    last_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs=model(inputs)\n",
    "            \n",
    "            loss = loss_fn(outputs,labels)\n",
    "            running_loss +=loss.item()\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            # if wandb!=None:\n",
    "                \n",
    "                # Accuracy(preds, labels)\n",
    "                # # precision(preds, labels)\n",
    "                # # recall(preds, labels)\n",
    "                # # f1(preds, labels)\n",
    "                # # wandb.log({\"accuracy\": accuracy.compute(), \"precision\": precision.compute(), \"recall\": recall.compute(), \"f1\": f1.compute()})\n",
    "                # wandb.log({\"vloss\":loss.item(),\"accuracy\": ((preds == labels).sum())/len(labels).compute()})\n",
    "    \n",
    "                # # Reset metrics\n",
    "                # Accuracy.reset()\n",
    "                # # precision.reset()\n",
    "                # # recall.reset()\n",
    "                # # f1.reset()\n",
    "    accuracy = correct/len(test_loader.dataset)\n",
    "    return running_loss/len(test_loader.dataset) , accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de2445f-7bd0-40e1-8065-0223e76fbef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# writer = SummaryWriter('runs/mnist_trainer_{}'.format(timestamp))\n",
    "# epoch_number = 0\n",
    "\n",
    "# EPOCHS = 2\n",
    "\n",
    "# best_vloss = 1_000_000.\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "    \n",
    "#     print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    \n",
    "#     avg_loss = train_one_epoch(model,training_loader,loss_fn,optimizer,device,epoch_number, writer)\n",
    "#     avg_vloss,v_acc = test_one_epoch(model,validation_loader,loss_fn,device)\n",
    "    \n",
    "#     print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "#     # Log the running loss averaged per batch\n",
    "#     # for both training and validation\n",
    "#     writer.add_scalars('Training vs. Validation Loss',\n",
    "#                     { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "#                     epoch_number + 1)\n",
    "#     writer.flush()\n",
    "\n",
    "#     # Track best performance, and save the model's state\n",
    "#     if avg_vloss < best_vloss:\n",
    "#         best_vloss = avg_vloss\n",
    "#         model_path = './models/model_{}_{}'.format(timestamp, epoch_number)\n",
    "#         torch.save(model.state_dict(), model_path)\n",
    "\n",
    "#     epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc07d593-9712-4552-8602-cd837151ecb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = LeNet()\n",
    "saved_model.load_state_dict(torch.load(\"./models/model_20240306_121901_0\", map_location=device))\n",
    "saved_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c2ab5f9-b5d3-4cc6-909a-b72f0056c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987\n"
     ]
    }
   ],
   "source": [
    "saved_model.eval()\n",
    "\n",
    "correct =0\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "with torch.no_grad():\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vinputs,vlabels=vinputs.to(device),vlabels.to(device)\n",
    "        voutputs = saved_model(vinputs)\n",
    "\n",
    "        _,predicted = torch.max(voutputs,1)\n",
    "        correct += (predicted == vlabels).sum().item()\n",
    "accuracy = correct/len(validation_loader.dataset)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f2ba0-14a1-40d2-99fa-37dfbef96e65",
   "metadata": {},
   "source": [
    "### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351df866-985a-4f60-8740-fedb77e1105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd9626f-b1ed-461f-bfd0-30d807d96399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msriharib128\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5159602c-3897-4202-ac25-16d6b92fa475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/surya_ravindra/CV_A2/wandb/run-20240307_005445-0mx4xqk9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/0mx4xqk9' target=\"_blank\">1st run</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/0mx4xqk9' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/0mx4xqk9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 64, 'epoch': 10, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"CV_A1_Q2\",name = \"1st run\")\n",
    "wandb.config.learning_rate = 0.001\n",
    "wandb.config.batch_size = 64\n",
    "wandb.config.epoch = 10\n",
    "wandb.config.optimizer = \"adam\"\n",
    "pprint(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88529caf-8115-47fd-93ae-ee35fbe63b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=wandb.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45986e65-ab18-452e-882f-9544d5a29bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "training_loader,validation_loader = data_get_load(wandb.config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af0facb2-2cc9-476b-9fc4-5d6a8b51e982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0af116e7-c477-484a-a7b9-d563434416b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "# # Initialize metrics\n",
    "# num_classes = 10\n",
    "# accuracy = Accuracy(task='multiclass',num_classes=num_classes).to(device)\n",
    "# precision = Precision(task='multiclass', average='macro', num_classes=num_classes).to(device)\n",
    "# recall = Recall(task='multiclass', average='macro', num_classes=num_classes).to(device)\n",
    "# f1 = F1Score(task='multiclass', average='macro', num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcb208d3-46bf-4e03-97ec-19ebf2b1ca3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "100th batch => 1.0806842792034148\n",
      "200th batch => 0.278742106705904\n",
      "300th batch => 0.18545835487544537\n",
      "400th batch => 0.14566997803747653\n",
      "500th batch => 0.13438145775347948\n",
      "600th batch => 0.12050811596214771\n",
      "700th batch => 0.10242413160391152\n",
      "800th batch => 0.09857013694010675\n",
      "900th batch => 0.07522635676898062\n",
      "LOSS train 0.07522635676898062 valid 0.0011488795249490068 ACC 0.9773\n",
      "saved model to ./models/model_20240307_005452_0\n",
      "EPOCH 2:\n",
      "100th batch => 0.07315306286327541\n",
      "200th batch => 0.0692412838852033\n",
      "300th batch => 0.07584246435202659\n",
      "400th batch => 0.06203115314245224\n",
      "500th batch => 0.05894677390344441\n",
      "600th batch => 0.06735840604756958\n",
      "700th batch => 0.06499053363222629\n",
      "800th batch => 0.05043961589224637\n",
      "900th batch => 0.05441587164299563\n",
      "LOSS train 0.05441587164299563 valid 0.0006031600922862708 ACC 0.9875\n",
      "saved model to ./models/model_20240307_005452_1\n",
      "EPOCH 3:\n",
      "100th batch => 0.04953925197711215\n",
      "200th batch => 0.04277902920497581\n",
      "300th batch => 0.047060423730872575\n",
      "400th batch => 0.050112640890292826\n",
      "500th batch => 0.04921356723061763\n",
      "600th batch => 0.04804431633092463\n",
      "700th batch => 0.04559210575185716\n",
      "800th batch => 0.045744238218758254\n",
      "900th batch => 0.04957385607762262\n",
      "LOSS train 0.04957385607762262 valid 0.0006373461486466113 ACC 0.9867\n",
      "EPOCH 4:\n",
      "100th batch => 0.041501562644261865\n",
      "200th batch => 0.035342449942836536\n",
      "300th batch => 0.040666455181781205\n",
      "400th batch => 0.026963507924228906\n",
      "500th batch => 0.038618263983516955\n",
      "600th batch => 0.03658815311617218\n",
      "700th batch => 0.04200099469991983\n",
      "800th batch => 0.04037315160734579\n",
      "900th batch => 0.04039193350588903\n",
      "LOSS train 0.04039193350588903 valid 0.000556967630636791 ACC 0.9891\n",
      "saved model to ./models/model_20240307_005452_3\n",
      "EPOCH 5:\n",
      "100th batch => 0.029779715249314904\n",
      "200th batch => 0.02958809327916242\n",
      "300th batch => 0.03289693955070106\n",
      "400th batch => 0.029721929390216246\n",
      "500th batch => 0.031577791229356084\n",
      "600th batch => 0.03326537270564586\n",
      "700th batch => 0.026227957928786055\n",
      "800th batch => 0.029052968479227274\n",
      "900th batch => 0.041706203952198845\n",
      "LOSS train 0.041706203952198845 valid 0.0005829974255015259 ACC 0.9881\n",
      "EPOCH 6:\n",
      "100th batch => 0.02394347518318682\n",
      "200th batch => 0.025245543562923557\n",
      "300th batch => 0.025452126353629864\n",
      "400th batch => 0.027232928211742547\n",
      "500th batch => 0.025104002834996208\n",
      "600th batch => 0.026831148330238648\n",
      "700th batch => 0.022383243995718657\n",
      "800th batch => 0.03188643878791481\n",
      "900th batch => 0.030003490957606117\n",
      "LOSS train 0.030003490957606117 valid 0.0005089329073649423 ACC 0.9902\n",
      "saved model to ./models/model_20240307_005452_5\n",
      "EPOCH 7:\n",
      "100th batch => 0.0146178188174963\n",
      "200th batch => 0.02285477012526826\n",
      "300th batch => 0.01780804051537416\n",
      "400th batch => 0.02344394206185825\n",
      "500th batch => 0.023272965565847698\n",
      "600th batch => 0.019978840225667226\n",
      "700th batch => 0.0243521542972303\n",
      "800th batch => 0.02616809210710926\n",
      "900th batch => 0.024292778473463842\n",
      "LOSS train 0.024292778473463842 valid 0.0006769239096813863 ACC 0.9859\n",
      "EPOCH 8:\n",
      "100th batch => 0.014285356395703275\n",
      "200th batch => 0.016153448617696995\n",
      "300th batch => 0.01768790515823639\n",
      "400th batch => 0.021795592312992086\n",
      "500th batch => 0.026784162430558353\n",
      "600th batch => 0.017895941608585417\n",
      "700th batch => 0.0224620886874618\n",
      "800th batch => 0.018434233612642858\n",
      "900th batch => 0.02508223578595789\n",
      "LOSS train 0.02508223578595789 valid 0.0006178392633700242 ACC 0.9888\n",
      "EPOCH 9:\n",
      "100th batch => 0.011523913509809063\n",
      "200th batch => 0.01816022731254634\n",
      "300th batch => 0.018368499268835877\n",
      "400th batch => 0.012892301012179815\n",
      "500th batch => 0.01815614751103567\n",
      "600th batch => 0.020386460278823505\n",
      "700th batch => 0.0169969653392036\n",
      "800th batch => 0.020206842198967935\n",
      "900th batch => 0.01937909243395552\n",
      "LOSS train 0.01937909243395552 valid 0.0005488996852256605 ACC 0.9907\n",
      "EPOCH 10:\n",
      "100th batch => 0.011555877961509396\n",
      "200th batch => 0.017742109104437985\n",
      "300th batch => 0.010086576569738099\n",
      "400th batch => 0.013399425078750938\n",
      "500th batch => 0.01648278219392523\n",
      "600th batch => 0.019791832459468424\n",
      "700th batch => 0.020497193938936106\n",
      "800th batch => 0.015867773562349613\n",
      "900th batch => 0.018336129262315808\n",
      "LOSS train 0.018336129262315808 valid 0.0005751876987380456 ACC 0.9906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇▇█▅▇██</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▂▂▂▁▁</td></tr><tr><td>vloss</td><td>█▂▂▂▂▁▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9906</td></tr><tr><td>train_loss</td><td>0.01834</td></tr><tr><td>vloss</td><td>0.00058</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">1st run</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/0mx4xqk9' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/0mx4xqk9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_005445-0mx4xqk9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "best_vloss = 1_000_000.\n",
    "# Training loop\n",
    "for epoch_number in range(wandb.config.epoch):  # Number of epochs\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    avg_loss = train_one_epoch(model,training_loader,loss_fn,optimizer,device,epoch_number,None,None,write=False)\n",
    "    avg_vloss,v_acc = test_one_epoch(model,validation_loader,loss_fn,device,None)\n",
    "\n",
    "    wandb.log({\"train_loss\":avg_loss,\"vloss\":avg_vloss,\"accuracy\":v_acc})\n",
    "    \n",
    "    print('LOSS train {} valid {} ACC {}'.format(avg_loss, avg_vloss,v_acc))\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = './models/model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"saved model to {model_path}\")\n",
    "\n",
    "# exort to ONNX and save in Netron for Vizualization\n",
    "wandb.save(\"model.pth\")\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66509d4-1b6c-4bae-b223-58b1722178ac",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31a1128a-1b02-4b5d-95f2-c692d8aa7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(model, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "253ef343-8cc9-43db-8268-c3a372df04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_sweep=[]\n",
    "accuracies_sweep=[]\n",
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        pprint(wandb.config)\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        training_loader,validation_loader = data_get_load(wandb.config.batch_size)\n",
    "        \n",
    "        model = LeNet()\n",
    "        model.to(device)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "\n",
    "        for epoch_number in range(config.epochs):\n",
    "            avg_loss = train_one_epoch(model,training_loader,loss_fn,optimizer,device,epoch_number,None,None,write=False)\n",
    "            avg_vloss,v_acc = test_one_epoch(model,validation_loader,loss_fn,device,None)\n",
    "            print('EPOCH {}  LOSS train {} valid {} ACC {}'.format(epoch_number,avg_loss, avg_vloss,v_acc))\n",
    "        \n",
    "            wandb.log({\"train_loss\":avg_loss,\"vloss\":avg_vloss,\"accuracy\":v_acc})\n",
    "        configs_sweep.append(wandb.config)\n",
    "        accuracies_sweep.append(v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3545231-bf00-46f3-8e4a-3f6f15b1fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep Configuration\n",
    "sweep_config = {\n",
    "    'method': 'random', # Use random search strategy\n",
    "    'metric': { # The metric that you want to optimize\n",
    "        'name': 'v_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': { # The hyperparameters to tune\n",
    "        'learning_rate': {  # Learning rate for the optimizer\n",
    "            'values': [0.001,  0.01,  0.1]\n",
    "        },\n",
    "        'optimizer': {  # The optimizer to use\n",
    "            'values': ['sgd', 'adam']\n",
    "        },\n",
    "        # 'dropout': {    # The dropout to use\n",
    "        #     'values': [0.2,  0.3,  0.5]\n",
    "        # },\n",
    "        'batch_size': {    # The batch size\n",
    "            'values': [8, 32,  64,  128]\n",
    "        },\n",
    "        'epochs': {    # The number of epochs\n",
    "            'values': [1, 2, 5]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20da1acb-db5a-40e9-aca5-08308f3b02fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: n67d31si\n",
      "Sweep URL: https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"CV_A1_Q2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38f1c9c6-7b27-471b-9f8b-d71ca755616f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sde5nc2g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/surya_ravindra/CV_A2/wandb/run-20240307_073228-sde5nc2g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/sde5nc2g' target=\"_blank\">crisp-sweep-1</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/sde5nc2g' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/sde5nc2g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8, 'epochs': 2, 'learning_rate': 0.01, 'optimizer': 'sgd'}\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n",
      "991th batch => 6.199817708885821\n",
      "1991th batch => 1.9512392409095447\n",
      "2991th batch => 1.4760686647960757\n",
      "3991th batch => 1.4342516511253416\n",
      "4991th batch => 1.363316169644786\n",
      "5991th batch => 1.0689968463997501\n",
      "6991th batch => 0.9770755575004568\n",
      "EPOCH 0  LOSS train 0.9770755575004568 valid 0.009310698428575875 ACC 0.9801\n",
      "991th batch => 0.8658552823110471\n",
      "1991th batch => 0.9081417675380521\n",
      "2991th batch => 0.8081263348053176\n",
      "3991th batch => 0.8740566581206304\n",
      "4991th batch => 0.8828560253883018\n",
      "5991th batch => 0.6761636387081168\n",
      "6991th batch => 0.7688354334256431\n",
      "EPOCH 1  LOSS train 0.7688354334256431 valid 0.010729170000831527 ACC 0.9772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>vloss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9772</td></tr><tr><td>train_loss</td><td>0.76884</td></tr><tr><td>vloss</td><td>0.01073</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crisp-sweep-1</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/sde5nc2g' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/sde5nc2g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_073228-sde5nc2g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5d5sx3tb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/surya_ravindra/CV_A2/wandb/run-20240307_073419-5d5sx3tb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/5d5sx3tb' target=\"_blank\">volcanic-sweep-2</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/5d5sx3tb' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/5d5sx3tb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'epochs': 2, 'learning_rate': 0.01, 'optimizer': 'adam'}\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n",
      "991th batch => 5.9535355256717954\n",
      "1991th batch => 3.643395198010767\n",
      "2991th batch => 3.246582798172531\n",
      "3991th batch => 3.1055301993461852\n",
      "4991th batch => 2.992721924104635\n",
      "5991th batch => 3.450461768097903\n",
      "6991th batch => 2.782694114650494\n",
      "EPOCH 0  LOSS train 2.782694114650494 valid 0.004004671387956477 ACC 0.9382\n",
      "991th batch => 2.464102068541033\n",
      "1991th batch => 2.6414060895377394\n",
      "2991th batch => 3.8021285598175405\n",
      "3991th batch => 2.8518025973479326\n",
      "4991th batch => 2.76539727376934\n",
      "5991th batch => 2.435629045981859\n",
      "6991th batch => 2.917860223295287\n",
      "EPOCH 1  LOSS train 2.917860223295287 valid 0.00445732772985939 ACC 0.9338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▁</td></tr><tr><td>train_loss</td><td>▁█</td></tr><tr><td>vloss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9338</td></tr><tr><td>train_loss</td><td>2.91786</td></tr><tr><td>vloss</td><td>0.00446</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">volcanic-sweep-2</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/5d5sx3tb' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/5d5sx3tb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_073419-5d5sx3tb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gskk3bky with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28882d5eb3fd4466ad8d86796d55403f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111341691058543, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/surya_ravindra/CV_A2/wandb/run-20240307_073606-gskk3bky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/gskk3bky' target=\"_blank\">jolly-sweep-3</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/gskk3bky' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/gskk3bky</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8, 'epochs': 5, 'learning_rate': 0.01, 'optimizer': 'sgd'}\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n",
      "991th batch => 5.555144281192334\n",
      "1991th batch => 1.9606740361348238\n",
      "2991th batch => 1.6434143149103055\n",
      "3991th batch => 1.3617520053270709\n",
      "4991th batch => 1.2111913919699646\n",
      "5991th batch => 1.0585869540745398\n",
      "6991th batch => 0.9975825737698892\n",
      "EPOCH 0  LOSS train 0.9975825737698892 valid 0.011156678332335133 ACC 0.9759\n",
      "991th batch => 0.8965585691227651\n",
      "1991th batch => 0.8465718136889282\n",
      "2991th batch => 0.875246096716833\n",
      "3991th batch => 1.0381276281927228\n",
      "4991th batch => 0.8737072891670356\n",
      "5991th batch => 0.8787772647239762\n",
      "6991th batch => 0.7612336578960313\n",
      "EPOCH 1  LOSS train 0.7612336578960313 valid 0.01093846969395756 ACC 0.9752\n",
      "991th batch => 0.7473053605409187\n",
      "1991th batch => 0.7602576802508585\n",
      "2991th batch => 0.7190579896600253\n",
      "3991th batch => 0.7655185304154587\n",
      "4991th batch => 0.7775383908089682\n",
      "5991th batch => 0.8670465260989808\n",
      "6991th batch => 0.8775461859817191\n",
      "EPOCH 2  LOSS train 0.8775461859817191 valid 0.009886846086517284 ACC 0.9822\n",
      "991th batch => 0.6617416968536658\n",
      "1991th batch => 0.6730620270224813\n",
      "2991th batch => 0.6123757271146465\n",
      "3991th batch => 0.7992551562870334\n",
      "4991th batch => 0.8119759058800247\n",
      "5991th batch => 0.7199726748297043\n",
      "6991th batch => 0.6037503071599518\n",
      "EPOCH 3  LOSS train 0.6037503071599518 valid 0.009049788737061628 ACC 0.9811\n",
      "991th batch => 0.5883445367136872\n",
      "1991th batch => 0.6705109417385156\n",
      "2991th batch => 0.6789249165392988\n",
      "3991th batch => 0.8184097768142717\n",
      "4991th batch => 0.6468772242757487\n",
      "5991th batch => 0.6570493834599516\n",
      "6991th batch => 0.7737156943993029\n",
      "EPOCH 4  LOSS train 0.7737156943993029 valid 0.010331586618186544 ACC 0.9817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▂▁█▇▇</td></tr><tr><td>train_loss</td><td>█▄▆▁▄</td></tr><tr><td>vloss</td><td>█▇▄▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9817</td></tr><tr><td>train_loss</td><td>0.77372</td></tr><tr><td>vloss</td><td>0.01033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jolly-sweep-3</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/gskk3bky' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/gskk3bky</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_073606-gskk3bky/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: md0ua9ae with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/surya_ravindra/CV_A2/wandb/run-20240307_073938-md0ua9ae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/md0ua9ae' target=\"_blank\">leafy-sweep-4</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/md0ua9ae' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/md0ua9ae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n",
      "991th batch => 18.251741362810137\n",
      "1991th batch => 3.6916667104233056\n",
      "2991th batch => 2.225923065857496\n",
      "3991th batch => 1.6432018884108401\n",
      "4991th batch => 1.3863097810960607\n",
      "5991th batch => 1.262583292920026\n",
      "6991th batch => 1.0538932435296011\n",
      "EPOCH 0  LOSS train 1.0538932435296011 valid 0.0005787050933082355 ACC 0.9766\n",
      "991th batch => 0.8185956264671403\n",
      "1991th batch => 0.8079232912659791\n",
      "2991th batch => 0.7871296330192127\n",
      "3991th batch => 0.8793787902929762\n",
      "4991th batch => 0.8212653600725752\n",
      "5991th batch => 0.7263649462335888\n",
      "6991th batch => 0.6841008702052204\n",
      "EPOCH 1  LOSS train 0.6841008702052204 valid 0.0004645774460863322 ACC 0.9808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>vloss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9808</td></tr><tr><td>train_loss</td><td>0.6841</td></tr><tr><td>vloss</td><td>0.00046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-sweep-4</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/md0ua9ae' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/md0ua9ae</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_073938-md0ua9ae/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cle36q8b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5266f2e38924057bcc8b858c0d5965c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113519438852866, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/surya_ravindra/CV_A2/wandb/run-20240307_074119-cle36q8b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/cle36q8b' target=\"_blank\">misunderstood-sweep-5</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/cle36q8b' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/cle36q8b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'epochs': 5, 'learning_rate': 0.1, 'optimizer': 'adam'}\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n",
      "991th batch => 43.176880449056625\n",
      "1991th batch => 23.25671637058258\n",
      "2991th batch => 23.26226585149765\n",
      "3991th batch => 23.29083756685257\n",
      "4991th batch => 23.300664513111116\n",
      "5991th batch => 23.28980432987213\n",
      "6991th batch => 23.253890569210053\n",
      "EPOCH 0  LOSS train 23.253890569210053 valid 0.07289276967048645 ACC 0.0974\n",
      "991th batch => 23.04339464187622\n",
      "1991th batch => 23.26725379943848\n",
      "2991th batch => 23.270063302516938\n",
      "3991th batch => 23.266925988197325\n",
      "4991th batch => 23.293243842124937\n",
      "5991th batch => 23.286218147277832\n",
      "6991th batch => 23.263929541110993\n",
      "EPOCH 1  LOSS train 23.263929541110993 valid 0.0730980437040329 ACC 0.1009\n",
      "991th batch => 23.04179944753647\n",
      "1991th batch => 23.270401695966722\n",
      "2991th batch => 23.290198802947998\n",
      "3991th batch => 23.2828069460392\n",
      "4991th batch => 23.284330325126646\n",
      "5991th batch => 23.26169182538986\n",
      "6991th batch => 23.278207147121428\n",
      "EPOCH 2  LOSS train 23.278207147121428 valid 0.07326645541191101 ACC 0.0974\n",
      "991th batch => 23.050361878871918\n",
      "1991th batch => 23.2461879491806\n",
      "2991th batch => 23.273120167255403\n",
      "3991th batch => 23.317230825424193\n",
      "4991th batch => 23.28665799856186\n",
      "5991th batch => 23.28820059299469\n",
      "6991th batch => 23.255355541706084\n",
      "EPOCH 3  LOSS train 23.255355541706084 valid 0.07278175203800201 ACC 0.1032\n",
      "991th batch => 23.094008643627166\n",
      "1991th batch => 23.288456163406373\n",
      "2991th batch => 23.25646839618683\n",
      "3991th batch => 23.295311245918274\n",
      "4991th batch => 23.2604195189476\n",
      "5991th batch => 23.26433340549469\n",
      "6991th batch => 23.318084907531738\n",
      "EPOCH 4  LOSS train 23.318084907531738 valid 0.07273831684589387 ACC 0.0958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5235c60cd9254fc3b80f57484639139f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▃▆▃█▁</td></tr><tr><td>train_loss</td><td>▁▂▄▁█</td></tr><tr><td>vloss</td><td>▃▆█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.0958</td></tr><tr><td>train_loss</td><td>23.31808</td></tr><tr><td>vloss</td><td>0.07274</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-sweep-5</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/cle36q8b' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/cle36q8b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_074119-cle36q8b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7wvjejpc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/surya_ravindra/CV_A2/wandb/run-20240307_074520-7wvjejpc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/7wvjejpc' target=\"_blank\">trim-sweep-6</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/sweeps/n67d31si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/7wvjejpc' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/7wvjejpc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8, 'epochs': 5, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n",
      "991th batch => 19.726857138574122\n",
      "1991th batch => 3.814682405143976\n",
      "2991th batch => 2.160127644990571\n",
      "3991th batch => 1.648054756843485\n",
      "4991th batch => 1.395670606972999\n",
      "5991th batch => 1.26193905666325\n",
      "6991th batch => 1.017983746008831\n",
      "EPOCH 0  LOSS train 1.017983746008831 valid 0.009516581569721166 ACC 0.9754\n",
      "991th batch => 0.7380682827746204\n",
      "1991th batch => 0.8154659192747203\n",
      "2991th batch => 0.7667398886381125\n",
      "3991th batch => 0.7661959799614851\n",
      "4991th batch => 0.6901234278800257\n",
      "5991th batch => 0.6469269450075807\n",
      "6991th batch => 0.6675393139977314\n",
      "EPOCH 1  LOSS train 0.6675393139977314 valid 0.005608304884928657 ACC 0.9837\n",
      "991th batch => 0.6015153157677924\n",
      "1991th batch => 0.5060312783921836\n",
      "2991th batch => 0.4802379263797411\n",
      "3991th batch => 0.5308238622986391\n",
      "4991th batch => 0.52842489370978\n",
      "5991th batch => 0.49618744035564305\n",
      "6991th batch => 0.48734701479028447\n",
      "EPOCH 2  LOSS train 0.48734701479028447 valid 0.004863912858832919 ACC 0.9875\n",
      "991th batch => 0.39806243007652936\n",
      "1991th batch => 0.36421483871907184\n",
      "2991th batch => 0.460744151133149\n",
      "3991th batch => 0.38017746783380973\n",
      "4991th batch => 0.3894086594177588\n",
      "5991th batch => 0.4110230622038398\n",
      "6991th batch => 0.4470828945476205\n",
      "EPOCH 3  LOSS train 0.4470828945476205 valid 0.004356926870960842 ACC 0.9887\n",
      "991th batch => 0.29121266348109204\n",
      "1991th batch => 0.30018314111801375\n",
      "2991th batch => 0.3331000683323782\n",
      "3991th batch => 0.36571788512814235\n",
      "4991th batch => 0.312846156973269\n",
      "5991th batch => 0.29497438327000963\n",
      "6991th batch => 0.38530146169720864\n",
      "EPOCH 4  LOSS train 0.38530146169720864 valid 0.004267055402634696 ACC 0.989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3d151c683f455a9b03b144514f6d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▇██</td></tr><tr><td>train_loss</td><td>█▄▂▂▁</td></tr><tr><td>vloss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.989</td></tr><tr><td>train_loss</td><td>0.3853</td></tr><tr><td>vloss</td><td>0.00427</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-sweep-6</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/7wvjejpc' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/7wvjejpc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_074520-7wvjejpc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train, count=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02bd67bd-28d8-4b37-8a58-8d266a5204c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8, 'epochs': 2, 'learning_rate': 0.01, 'optimizer': 'sgd'} 0.9772\n",
      "{'batch_size': 64, 'epochs': 2, 'learning_rate': 0.01, 'optimizer': 'adam'} 0.9338\n",
      "{'batch_size': 8, 'epochs': 5, 'learning_rate': 0.01, 'optimizer': 'sgd'} 0.9817\n",
      "{'batch_size': 128, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'} 0.9808\n",
      "{'batch_size': 32, 'epochs': 5, 'learning_rate': 0.1, 'optimizer': 'adam'} 0.0958\n",
      "{'batch_size': 8, 'epochs': 5, 'learning_rate': 0.001, 'optimizer': 'sgd'} 0.989\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(configs_sweep[i],accuracies_sweep[i])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c39e1e50-c17a-4169-982e-632d6c1849cd",
   "metadata": {},
   "source": [
    "{'batch_size': 8, 'epochs': 2, 'learning_rate': 0.01, 'optimizer': 'sgd'} 0.9772\n",
    "{'batch_size': 64, 'epochs': 2, 'learning_rate': 0.01, 'optimizer': 'adam'} 0.9338\n",
    "{'batch_size': 8, 'epochs': 5, 'learning_rate': 0.01, 'optimizer': 'sgd'} 0.9817\n",
    "{'batch_size': 128, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'} 0.9808\n",
    "{'batch_size': 32, 'epochs': 5, 'learning_rate': 0.1, 'optimizer': 'adam'} 0.0958\n",
    "{'batch_size': 8, 'epochs': 5, 'learning_rate': 0.001, 'optimizer': 'sgd'} 0.989\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04428c98-e367-4363-ad8a-72d1d402ad0d",
   "metadata": {},
   "source": [
    "1. **Batch Size Impact:**\n",
    "   - Comparing 1st and 2nd run, lower batch size resulted in better accuracy.\n",
    "   \n",
    "2. **Epochs Influence:**\n",
    "   - Increasing the number of epochs led to higher accuracy, indicating improved performance as the model trained for a longer duration.\n",
    "   \n",
    "3. **Learning Rate Observation:**\n",
    "   - Lower learning rate contributed to better accuracy, but it comes at the cost of increased model training time.\n",
    "   \n",
    "4. **Optimizer Effect:**\n",
    "   - Stochastic Gradient Descent (SGD) optimizer yielded better accuracy compared to adam optimizers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266a8b9-386b-4031-9a48-e6520c2d8f08",
   "metadata": {},
   "source": [
    "## CNN vs SIFT-BoVW-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0825b9-cce6-4b37-9566-53786c39233d",
   "metadata": {},
   "source": [
    "- **Accuracy:** CNN achieved 98.9%, while SIFT-BoVW-SVM had 75% accuracy.\n",
    "  \n",
    "- **Feature Representation:** CNN learns features automatically, eliminating manual feature engineering. SIFT-BoVW-SVM relies on handcrafted features.\n",
    "\n",
    "- **Complexity and Expressiveness:** CNN captures complex patterns and relationships more effectively than SIFT-BoVW-SVM.\n",
    "\n",
    "- **End-to-End Learning:** CNN supports end-to-end learning, jointly optimizing feature representation and classification. SIFT-BoVW-SVM has separate steps for feature extraction and classification.\n",
    "\n",
    "- **Data Requirements:** CNNs may need more labeled data but generalize well with sufficient data. SIFT-BoVW-SVM's performance may be more dependent on the quality and quantity of handcrafted features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647713ca-f1ff-42a3-9679-5a2b65dd6759",
   "metadata": {},
   "source": [
    "## Double the number of convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb06e344-fdec-46d8-b4ca-b46f9fd1738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d91df8f5-0690-4de0-8ba8-fb7ba9d7e5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msriharib128\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9809273d-11a9-4d81-94dd-3aa94ad3b764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d085d3be4d406dbf8db66f40432135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114909633331789, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240307_231505-x2x2mxdu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/x2x2mxdu' target=\"_blank\">double conv layers</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/x2x2mxdu' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/x2x2mxdu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"CV_A1_Q2\",name = \"double conv layers\")\n",
    "wandb.config.learning_rate = 0.001\n",
    "wandb.config.batch_size = 8\n",
    "wandb.config.epoch = 5\n",
    "wandb.config.optimizer = \"sgd\"\n",
    "pprint(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f81a3f6a-e120-4767-807d-a236896c5e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet2(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (fc1): Linear(in_features=64, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class LeNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5,padding=(2,2))\n",
    "        self.conv4 = nn.Conv2d(32, 64, 5,padding=(2,2))\n",
    "        self.fc1 = nn.Linear(64 * 1 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 64 * 1 *1)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet2()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d59cf5c2-0a38-459c-8475-e7e118985630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet2()\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = build_optimizer(model, wandb.config.optimizer, wandb.config.learning_rate)\n",
    "# torch.optim.Adam(model.parameters(),lr=wandb.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6232f504-25b9-4677-9985-0eee68ce6e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "training_loader,validation_loader = data_get_load(wandb.config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "869a3ea1-a235-42a3-aaed-331f2d327db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "1000th batch => 23.028387405872344\n",
      "2000th batch => 23.001312878131866\n",
      "3000th batch => 22.98625853061676\n",
      "4000th batch => 22.91183021068573\n",
      "5000th batch => 19.91512724339962\n",
      "6000th batch => 6.315912722367793\n",
      "7000th batch => 2.7253219169564544\n",
      "LOSS train 2.7253219169564544 valid 0.02039045814400306 ACC 0.9484\n",
      "EPOCH 2:\n",
      "1000th batch => 1.8402202100038993\n",
      "2000th batch => 1.4166509025910636\n",
      "3000th batch => 1.6317249012331012\n",
      "4000th batch => 1.304414498451224\n",
      "5000th batch => 1.1063491380820052\n",
      "6000th batch => 1.074627980129153\n",
      "7000th batch => 0.8837914431348327\n",
      "LOSS train 0.8837914431348327 valid 0.010015158806715043 ACC 0.9756\n",
      "EPOCH 3:\n",
      "1000th batch => 0.869344145450741\n",
      "2000th batch => 0.8572535915592016\n",
      "3000th batch => 0.7859892394479538\n",
      "4000th batch => 0.801007483030553\n",
      "5000th batch => 0.6472502054757205\n",
      "6000th batch => 0.7214033087166899\n",
      "7000th batch => 0.617480428050767\n",
      "LOSS train 0.617480428050767 valid 0.009370210536742524 ACC 0.9768\n",
      "EPOCH 4:\n",
      "1000th batch => 0.522015940071833\n",
      "2000th batch => 0.5930709003719676\n",
      "3000th batch => 0.5140354790752099\n",
      "4000th batch => 0.5490413363377593\n",
      "5000th batch => 0.5975693562747256\n",
      "6000th batch => 0.5301193176995003\n",
      "7000th batch => 0.5965431164834808\n",
      "LOSS train 0.5965431164834808 valid 0.005999225016954005 ACC 0.9845\n",
      "EPOCH 5:\n",
      "1000th batch => 0.4481095856048523\n",
      "2000th batch => 0.3960677568632491\n",
      "3000th batch => 0.38424891987103366\n",
      "4000th batch => 0.46198155804268026\n",
      "5000th batch => 0.4016575822957384\n",
      "6000th batch => 0.39954897398016326\n",
      "7000th batch => 0.4812590753148106\n",
      "LOSS train 0.4812590753148106 valid 0.005482541751986355 ACC 0.9858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆██</td></tr><tr><td>train_loss</td><td>█▂▁▁▁</td></tr><tr><td>vloss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9858</td></tr><tr><td>train_loss</td><td>0.48126</td></tr><tr><td>vloss</td><td>0.00548</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">double conv layers</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/x2x2mxdu' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/x2x2mxdu</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v0' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_231505-x2x2mxdu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_vloss = 1_000_000.\n",
    "# Training loop\n",
    "for epoch_number in range(wandb.config.epoch):  # Number of epochs\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    avg_loss = train_one_epoch(model,training_loader,loss_fn,optimizer,device,epoch_number,None,None,write=False)\n",
    "    avg_vloss,v_acc = test_one_epoch(model,validation_loader,loss_fn,device,None)\n",
    "\n",
    "    wandb.log({\"train_loss\":avg_loss,\"vloss\":avg_vloss,\"accuracy\":v_acc})\n",
    "    \n",
    "    print('LOSS train {} valid {} ACC {}'.format(avg_loss, avg_vloss,v_acc))\n",
    "\n",
    "# exort to ONNX and save in Netron for Vizualization\n",
    "wandb.save(\"model.pth\")\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b09efe-6ae2-44ce-a81f-2af015747253",
   "metadata": {},
   "source": [
    "- **Effect of Doubling Convolutional Layers:**\n",
    "  - Increasing the number of convolutional layers leads to a more complex model but it may lead to overfitting\n",
    "  - We need to experiment with some other setting of hyperparameters\n",
    "  - Regularization techniques may be needed to prevent overfitting with this more complex architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01f7e8-aecd-4d76-8e82-c414027984e9",
   "metadata": {},
   "source": [
    "## Changing Training Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a0be25c-3f7b-44a7-8a5b-c6f0d85a6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "def data_get_load_num_samp(batch_size=64, num_training_samples=600):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # Create datasets for training & validation, download if necessary\n",
    "    training_set = datasets.MNIST('./data', train=True, transform=transform, download=True)\n",
    "    validation_set = datasets.MNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "    if num_training_samples == len(training_set):\n",
    "        subset_train_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        subset_indices = []\n",
    "        for class_label in range(10): \n",
    "            class_indices = [i for i, (_, label) in enumerate(training_set) if label == class_label]\n",
    "            subset_indices.extend(class_indices[:num_training_samples // 10])\n",
    "        class_weights = [1.0] * len(training_set)\n",
    "        for i in subset_indices:\n",
    "            class_weights[i] = num_training_samples / len(subset_indices)\n",
    "    \n",
    "        subset_sampler = WeightedRandomSampler(weights=class_weights, num_samples=num_training_samples, replacement=True)\n",
    "\n",
    "        # sss = StratifiedShuffleSplit(n_splits=1, train_size=num_training_samples, random_state=42)\n",
    "        # indices = list(range(len(training_set)))\n",
    "\n",
    "        # for _, subset_indices in sss.split(indices, training_set.targets):\n",
    "        #     subset_train_dataset = torch.utils.data.Subset(training_set, subset_indices)\n",
    "\n",
    "        subset_train_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size,sampler=subset_sampler)\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Report split sizes\n",
    "    print('Training set has {} instances'.format(len(subset_train_loader)*batch_size))\n",
    "    print('Validation set has {} instances'.format(len(validation_set)))\n",
    "\n",
    "    return subset_train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4b432a2-4005-45a3-8487-5857b035b3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 600 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "batch_size = 8\n",
    "num_training_samples = 600\n",
    "training_loader, validation_loader = data_get_load_num_samp(batch_size, num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2ab5685-a64b-4316-b1a9-224904f0bd94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fadab9ec90e40b88daa0d9f7363d967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113950744442668, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_132926-3hn4ds1w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/3hn4ds1w' target=\"_blank\">600_sz_run</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/3hn4ds1w' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/3hn4ds1w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'sgd'}\n",
      "Training set has 600 instances\n",
      "Validation set has 10000 instances\n",
      "EPOCH 1:\n",
      "LOSS train 2.307764320373535 valid 0.2876749141931534 ACC 0.101\n",
      "EPOCH 2:\n",
      "LOSS train 2.2988914394378663 valid 0.287054532456398 ACC 0.1604\n",
      "EPOCH 3:\n",
      "LOSS train 2.2896838124593097 valid 0.2863978235721588 ACC 0.1589\n",
      "EPOCH 4:\n",
      "LOSS train 2.287605930964152 valid 0.28560271129608156 ACC 0.1746\n",
      "EPOCH 5:\n",
      "LOSS train 2.280446081161499 valid 0.28438931946754453 ACC 0.163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 15.1%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">600_sz_run</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/3hn4ds1w' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/3hn4ds1w</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_132926-3hn4ds1w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db4dd0f32a845d383980729ffab1ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111423263333159, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_133036-de0oi2v8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/de0oi2v8' target=\"_blank\">1800_sz_run</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/de0oi2v8' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/de0oi2v8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'sgd'}\n",
      "Training set has 1800 instances\n",
      "Validation set has 10000 instances\n",
      "EPOCH 1:\n",
      "LOSS train 2.299780142042372 valid 0.28666797893047335 ACC 0.1731\n",
      "EPOCH 2:\n",
      "LOSS train 2.2774820952945287 valid 0.2820217683076858 ACC 0.2768\n",
      "EPOCH 3:\n",
      "LOSS train 2.1561869176228843 valid 0.23829941967725754 ACC 0.392\n",
      "EPOCH 4:\n",
      "LOSS train 1.4438857014973958 valid 0.10895815367549658 ACC 0.7319\n",
      "EPOCH 5:\n",
      "LOSS train 0.6584513615734048 valid 0.06178232773728669 ACC 0.8454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">1800_sz_run</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/de0oi2v8' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/de0oi2v8</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_133036-de0oi2v8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d537cb915220468caf2fb86b172107fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114617111120929, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_133143-t15vdtem</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/t15vdtem' target=\"_blank\">6000_sz_run</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/t15vdtem' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/t15vdtem</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'sgd'}\n",
      "Training set has 6000 instances\n",
      "Validation set has 10000 instances\n",
      "EPOCH 1:\n",
      "LOSS train 2.217253108183543 valid 0.2078753121316433 ACC 0.4631\n",
      "EPOCH 2:\n",
      "LOSS train 0.7253771833752592 valid 0.04157514016944915 ACC 0.8922\n",
      "EPOCH 3:\n",
      "LOSS train 0.3045365705775718 valid 0.027306001936993562 ACC 0.9318\n",
      "EPOCH 4:\n",
      "LOSS train 0.23010187824598202 valid 0.021741925750183872 ACC 0.9453\n",
      "EPOCH 5:\n",
      "LOSS train 0.17464911114564166 valid 0.021707751736763748 ACC 0.9467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">6000_sz_run</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/t15vdtem' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/t15vdtem</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_133143-t15vdtem/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1817f2286a4fdda06d0f89f3730f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114621544442748, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_133256-ny9vrs4m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/ny9vrs4m' target=\"_blank\">18000_sz_run</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/ny9vrs4m' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/ny9vrs4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'sgd'}\n",
      "Training set has 18000 instances\n",
      "Validation set has 10000 instances\n",
      "EPOCH 1:\n",
      "1000th batch => 19.906529293060302\n",
      "2000th batch => 3.740486343605444\n",
      "LOSS train 3.740486343605444 valid 0.023452815829147586 ACC 0.9398\n",
      "EPOCH 2:\n",
      "1000th batch => 1.8371229510509874\n",
      "2000th batch => 1.532748349781614\n",
      "LOSS train 1.532748349781614 valid 0.014218656379112508 ACC 0.9654\n",
      "EPOCH 3:\n",
      "1000th batch => 1.0637238716251158\n",
      "2000th batch => 1.0895444704356487\n",
      "LOSS train 1.0895444704356487 valid 0.012735238711860438 ACC 0.9677\n",
      "EPOCH 4:\n",
      "1000th batch => 0.8859405839355895\n",
      "2000th batch => 0.8796252251890837\n",
      "LOSS train 0.8796252251890837 valid 0.008859312231723015 ACC 0.9769\n",
      "EPOCH 5:\n",
      "1000th batch => 0.7271335385193379\n",
      "2000th batch => 0.6444843176971699\n",
      "LOSS train 0.6444843176971699 valid 0.007863257527615132 ACC 0.9796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">18000_sz_run</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/ny9vrs4m' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/ny9vrs4m</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_133256-ny9vrs4m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8567ac0adfd84d9ba11d4492bdec6c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114275277779799, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_133424-273f164s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/273f164s' target=\"_blank\">60000_sz_run</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/273f164s' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/273f164s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'sgd'}\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n",
      "EPOCH 1:\n",
      "1000th batch => 19.734200779795646\n",
      "2000th batch => 3.898778458572924\n",
      "3000th batch => 1.9982943773898296\n",
      "4000th batch => 1.5118189847673056\n",
      "5000th batch => 1.237857185654575\n",
      "6000th batch => 1.1649340602968004\n",
      "7000th batch => 0.9770220842046546\n",
      "LOSS train 0.9770220842046546 valid 0.010974698905803234 ACC 0.9706\n",
      "EPOCH 2:\n",
      "1000th batch => 0.8914917239059287\n",
      "2000th batch => 0.8450065323522722\n",
      "3000th batch => 0.7256197151289234\n",
      "4000th batch => 0.7094172284578962\n",
      "5000th batch => 0.6193837518546207\n",
      "6000th batch => 0.5759707683456509\n",
      "7000th batch => 0.6693493179033976\n",
      "LOSS train 0.6693493179033976 valid 0.007008310264024476 ACC 0.981\n",
      "EPOCH 3:\n",
      "1000th batch => 0.5441190069946242\n",
      "2000th batch => 0.5636915128201871\n",
      "3000th batch => 0.5695956840901272\n",
      "4000th batch => 0.44531528656756564\n",
      "5000th batch => 0.5156718561313391\n",
      "6000th batch => 0.48283446466905844\n",
      "7000th batch => 0.4582971924614685\n",
      "LOSS train 0.4582971924614685 valid 0.006036223958357004 ACC 0.9851\n",
      "EPOCH 4:\n",
      "1000th batch => 0.3230785105612199\n",
      "2000th batch => 0.4199350328496439\n",
      "3000th batch => 0.4109226046806361\n",
      "4000th batch => 0.41982575745905704\n",
      "5000th batch => 0.39875870429264976\n",
      "6000th batch => 0.4181928372836046\n",
      "7000th batch => 0.4427912858915806\n",
      "LOSS train 0.4427912858915806 valid 0.005915064864575106 ACC 0.9858\n",
      "EPOCH 5:\n",
      "1000th batch => 0.3709562651031774\n",
      "2000th batch => 0.3212003323398903\n",
      "3000th batch => 0.3284671820322728\n",
      "4000th batch => 0.32560636151863037\n",
      "5000th batch => 0.3584299379644654\n",
      "6000th batch => 0.33911021078159137\n",
      "7000th batch => 0.3203715162921162\n",
      "LOSS train 0.3203715162921162 valid 0.004018521954791322 ACC 0.9898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">60000_sz_run</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/273f164s' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/273f164s</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_133424-273f164s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_szs = [600,1800,6000,18000,60000]\n",
    "accuracies_sz =[]\n",
    "for num_training_samples in training_szs:\n",
    "    # {'batch_size': 8, 'epochs': 5, 'learning_rate': 0.001, 'optimizer': 'sgd'} 0.989\n",
    "    run = wandb.init(project=\"CV_A1_Q2\",name = f\"{num_training_samples}_sz_run\")\n",
    "    wandb.config.learning_rate = 0.001\n",
    "    wandb.config.batch_size = 8\n",
    "    wandb.config.epoch = 5\n",
    "    wandb.config.optimizer = \"sgd\"\n",
    "    pprint(wandb.config)\n",
    "    \n",
    "    model = LeNet()\n",
    "    model.to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = build_optimizer(model, wandb.config.optimizer, wandb.config.learning_rate)\n",
    "    training_loader, validation_loader = data_get_load_num_samp(wandb.config.batch_size, num_training_samples)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch_number in range(wandb.config.epoch):  # Number of epochs\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "        avg_loss = train_one_epoch(model,training_loader,loss_fn,optimizer,device,epoch_number,None,None,write=False)\n",
    "        avg_vloss,v_acc = test_one_epoch(model,validation_loader,loss_fn,device,None)\n",
    "        # wandb.log({\"train_loss\":avg_loss,\"vloss\":avg_vloss,\"accuracy\":v_acc})\n",
    "        \n",
    "        print('LOSS train {} valid {} ACC {}'.format(avg_loss, avg_vloss,v_acc))\n",
    "    \n",
    "        # if avg_vloss < best_vloss:\n",
    "        #     best_vloss = avg_vloss\n",
    "        #     model_path = './models/model_{}_{}'.format(timestamp, epoch_number)\n",
    "        #     torch.save(model.state_dict(), model_path)\n",
    "        #     print(f\"saved model to {model_path}\")\n",
    "    accuracies_sz.append(v_acc)\n",
    "    # exort to ONNX and save in Netron for Vizualization\n",
    "    wandb.save(f\"model_sz_{num_training_samples}.pth\")\n",
    "    \n",
    "    # Finish the run\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2382e2a-e344-4a37-9a3f-9e55321c2e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.163, 0.8454, 0.9467, 0.9796, 0.9898]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_sz)\n",
    "with open(\"accuracies_sz.pkl\",\"wb\") as f:\n",
    "    pickle.dump(accuracies_sz,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "476d40cd-af6f-4d05-ad8d-c8d1391333f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_szs = [600,1800,6000,18000,60000]\n",
    "with open(\"accuracies_sz.pkl\",\"rb\") as f:\n",
    "    accuracies_sz = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e821caec-ab2e-4fd6-97c3-c8a1bec80524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.163, 0.8454, 0.9467, 0.9796, 0.9898]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45b34a07-3b2b-4bca-b00c-99c0d3a5e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_sz = accuracies_sz[4::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df16e5ba-078f-41c5-adb1-f428578aef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_szs,accuracies_sz);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db9761-432d-4738-bf46-099365b5a964",
   "metadata": {},
   "source": [
    "- **Effect of Increasing Training Samples:**\n",
    "  - As the number of training samples increases:\n",
    "    - Accuracy shows a noticeable improvement.\n",
    "    - With 600 samples, accuracy is relatively low at 16.3%.\n",
    "    - A substantial increase is observed with 1800 samples (84.54%).\n",
    "    - Further improvements are seen with 6000 (94.67%), 18000 (97.96%), and 60000 samples (98.98%).\n",
    "  - We can see significant performance improvement after 6000 samples only by adding large amount of data \n",
    "  - This trend suggests that having more diverse and abundant data positively impacts model performance, leading to better generalization and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e587b7c-8a0d-410a-a0e5-8830fda632e7",
   "metadata": {},
   "source": [
    "## TranformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39478cf4-45fd-46c3-9430-bb67867796cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Transformer Encoder Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        \n",
    "        # Self-attention layer\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        \n",
    "        # First linear layer and its normalization\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Second linear layer and its normalization\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # Self-attention layer\n",
    "        src1, _ = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Residual connection and dropout for the first sub-layer\n",
    "        src = src + self.dropout(src1)\n",
    "        \n",
    "        # Layer normalization for the first sub-layer\n",
    "        src = self.norm1(src)\n",
    "        \n",
    "        # First feedforward layer and its activation function\n",
    "        src2 = self.linear2(self.dropout(nn.functional.relu(self.linear1(src))))\n",
    "        \n",
    "        # Residual connection and dropout for the second sub-layer\n",
    "        src = src + self.dropout(src2)\n",
    "        \n",
    "        # Layer normalization for the second sub-layer\n",
    "        src = self.norm2(src)\n",
    "        \n",
    "        return src\n",
    "\n",
    "# ViT inspired classification head\n",
    "class ViTClassHead(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(ViTClassHead, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Vision Transformer\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, img_size=28, patch_size=7, in_chans=1, num_classes=10, d_model=512, nhead=8, num_layers=2):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        \n",
    "        # Patch Embedding\n",
    "        # Alternative patch embedding implementation\n",
    "        self.patch_embed = nn.Conv2d(in_chans, d_model, kernel_size=patch_size, stride=patch_size, bias=False)\n",
    "\n",
    "        # Positional Embedding => Batch size, number of patches + classification token, embedding dimension\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, (img_size // patch_size) ** 2 + 1, d_model))\n",
    "        \n",
    "        # Transformer Encoder Blocks\n",
    "        self.transformer_encoder = nn.Sequential(*[TransformerEncoderBlock(d_model, nhead) for _ in range(num_layers)])\n",
    "        \n",
    "        # Classification Head\n",
    "        self.classification_head = ViTClassHead(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten and embed patches\n",
    "        x = self.patch_embed(x)\n",
    "            # Flatten the spatial dimensions\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        # Concatenate positional embedding\n",
    "        x = torch.cat([x, self.pos_embed.expand(x.size(0), -1, -1)], dim=1)\n",
    "    \n",
    "        \n",
    "        # # Concatenate positional embedding\n",
    "        # x = torch.cat([x, self.pos_embed], dim=1)\n",
    "        \n",
    "        # Encode with Transformer layers\n",
    "        for layer in self.transformer_encoder:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Use the first token for classification (similar to ViT)\n",
    "        x = x[:, 0]\n",
    "        \n",
    "        # Use classification head\n",
    "        x = self.classification_head(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d5f09fd-6c55-41c8-a05b-42a76306e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8ac7714-7c99-4b27-997d-f23e3db7ec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2766624-7acb-418e-bf74-98b8323e5466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wqkktct3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>vloss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.1133</td></tr><tr><td>train_loss</td><td>22.8922</td></tr><tr><td>vloss</td><td>0.28634</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TransformerEncoder_60K</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/wqkktct3' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/wqkktct3</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_113130-wqkktct3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wqkktct3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed969264e03a499f8d4937fb32087429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114524077781122, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_114848-2lg2gbvt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/2lg2gbvt' target=\"_blank\">TransformerEncoder_6K</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/2lg2gbvt' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/2lg2gbvt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"CV_A1_Q2\",name = \"TransformerEncoder_6K\")\n",
    "wandb.config.learning_rate = 0.001\n",
    "wandb.config.batch_size = 8\n",
    "wandb.config.epoch = 5\n",
    "wandb.config.optimizer = \"adam\"\n",
    "pprint(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0dd0e651-6031-43a7-90b5-40e982861857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 6000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "# img_size = 28\n",
    "# patch_size = 7\n",
    "# in_chans = 1\n",
    "# num_classes = 10\n",
    "# d_model = 512\n",
    "# nhead = 8\n",
    "# num_layers = 2\n",
    "\n",
    "batch_size = wandb.config.batch_size\n",
    "learning_rate = wandb.config.learning_rate\n",
    "epochs = wandb.config.epoch\n",
    "\n",
    "num_training_samples = 6000\n",
    "# num_training_samples = 60000\n",
    "training_loader, validation_loader = data_get_load_num_samp(batch_size, num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84e126b2-021c-490a-b79e-f8bc172a01c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 2.4285778039296466 valid 0.29617088919878004 ACC 0.0974\n",
      "EPOCH 2:\n",
      "LOSS train 2.344162731170654 valid 0.2904565735578537 ACC 0.0958\n",
      "EPOCH 3:\n",
      "LOSS train 2.324161339441935 valid 0.28910494294166567 ACC 0.0982\n",
      "EPOCH 4:\n",
      "LOSS train 2.3165935697555544 valid 0.28804730880260465 ACC 0.1032\n",
      "EPOCH 5:\n",
      "LOSS train 2.3123336995442707 valid 0.2890615390062332 ACC 0.1032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▃▁▃██</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>vloss</td><td>█▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.1032</td></tr><tr><td>train_loss</td><td>2.31233</td></tr><tr><td>vloss</td><td>0.28906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TransformerEncoder_6K</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/2lg2gbvt' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/2lg2gbvt</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_114848-2lg2gbvt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Create an instance of the VisionTransformer model\n",
    "model = VisionTransformer(img_size=28, patch_size=7, in_chans=1, num_classes=10, d_model=512, nhead=8, num_layers=2)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = build_optimizer(model, wandb.config.optimizer, wandb.config.learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch_number in range(wandb.config.epoch):  # Number of epochs\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    avg_loss = train_one_epoch(model,training_loader,loss_fn,optimizer,device,epoch_number,None,None,write=False)\n",
    "    avg_vloss,v_acc = test_one_epoch(model,validation_loader,loss_fn,device,None)\n",
    "\n",
    "    wandb.log({\"train_loss\":avg_loss,\"vloss\":avg_vloss,\"accuracy\":v_acc})\n",
    "    \n",
    "    print('LOSS train {} valid {} ACC {}'.format(avg_loss, avg_vloss,v_acc))\n",
    "\n",
    "wandb.save(\"model_ViT_6k.pth\")\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4903b701-670b-4d29-a91b-df64e37c54c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6k ViT ==>  0.1032\n"
     ]
    }
   ],
   "source": [
    "print(\"6k ViT ==> \",v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f54a2687-ede2-4203-9d7f-8175a7a437d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bd3e6f1d0c43ae933252827c3ac9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114194066663509, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_115902-lk0qu8z0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/lk0qu8z0' target=\"_blank\">TransformerEncoder_60K</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/lk0qu8z0' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/lk0qu8z0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 8, 'epoch': 5, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"CV_A1_Q2\",name = \"TransformerEncoder_60K\")\n",
    "wandb.config.learning_rate = 0.001\n",
    "wandb.config.batch_size = 8\n",
    "wandb.config.epoch = 5\n",
    "wandb.config.optimizer = \"adam\"\n",
    "pprint(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22d278bf-b36a-412d-9468-ddf4f451969a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "batch_size = wandb.config.batch_size\n",
    "learning_rate = wandb.config.learning_rate\n",
    "epochs = wandb.config.epoch\n",
    "\n",
    "# num_training_samples = 6000\n",
    "num_training_samples = 60000\n",
    "training_loader, validation_loader = data_get_load_num_samp(batch_size, num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d585300-dcdd-4714-b470-aa845d9a2c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "1000th batch => 23.97429649233818\n",
      "2000th batch => 23.275395567417146\n",
      "3000th batch => 23.138217356204986\n",
      "4000th batch => 23.114233906269074\n",
      "5000th batch => 23.099473893642426\n",
      "6000th batch => 23.08377410173416\n",
      "7000th batch => 23.067642319202424\n",
      "LOSS train 23.067642319202424 valid 0.28894505922794345 ACC 0.1135\n",
      "EPOCH 2:\n",
      "1000th batch => 23.065022308826446\n",
      "2000th batch => 23.068981878757477\n",
      "3000th batch => 23.054460854530333\n",
      "4000th batch => 23.052577772140502\n",
      "5000th batch => 23.046558594703676\n",
      "6000th batch => 23.04300194501877\n",
      "7000th batch => 23.04064549446106\n",
      "LOSS train 23.04064549446106 valid 0.2876890215873718 ACC 0.1028\n",
      "EPOCH 3:\n",
      "1000th batch => 23.031053729057312\n",
      "2000th batch => 23.043004298210143\n",
      "3000th batch => 23.031435487270354\n",
      "4000th batch => 23.03174451828003\n",
      "5000th batch => 23.03488732814789\n",
      "6000th batch => 23.026367523670196\n",
      "7000th batch => 23.03998293161392\n",
      "LOSS train 23.03998293161392 valid 0.287713766336441 ACC 0.1135\n",
      "EPOCH 4:\n",
      "1000th batch => 23.027424533367157\n",
      "2000th batch => 23.03730814933777\n",
      "3000th batch => 23.02237199783325\n",
      "4000th batch => 23.028768215179444\n",
      "5000th batch => 23.02697909832001\n",
      "6000th batch => 23.03434068441391\n",
      "7000th batch => 23.029452970027922\n",
      "LOSS train 23.029452970027922 valid 0.2877727152585983 ACC 0.1135\n",
      "EPOCH 5:\n",
      "1000th batch => 23.028598630428313\n",
      "2000th batch => 23.024999351501464\n",
      "3000th batch => 23.023567776679993\n",
      "4000th batch => 23.03755440711975\n",
      "5000th batch => 23.02990929365158\n",
      "6000th batch => 23.02352565765381\n",
      "7000th batch => 23.040244839191438\n",
      "LOSS train 23.040244839191438 valid 0.2876365729093552 ACC 0.1135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 13.6%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▁███</td></tr><tr><td>train_loss</td><td>█▃▃▁▃</td></tr><tr><td>vloss</td><td>█▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.1135</td></tr><tr><td>train_loss</td><td>23.04024</td></tr><tr><td>vloss</td><td>0.28764</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TransformerEncoder_60K</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/lk0qu8z0' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/lk0qu8z0</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v3' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v3</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_115902-lk0qu8z0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Create an instance of the VisionTransformer model\n",
    "model = VisionTransformer(img_size=28, patch_size=7, in_chans=1, num_classes=10, d_model=512, nhead=8, num_layers=2)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = build_optimizer(model, wandb.config.optimizer, wandb.config.learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "for epoch_number in range(wandb.config.epoch):  # Number of epochs\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    avg_loss = train_one_epoch(model,training_loader,loss_fn,optimizer,device,epoch_number,None,None,write=False)\n",
    "    avg_vloss,v_acc = test_one_epoch(model,validation_loader,loss_fn,device,None)\n",
    "\n",
    "    wandb.log({\"train_loss\":avg_loss,\"vloss\":avg_vloss,\"accuracy\":v_acc})\n",
    "    \n",
    "    print('LOSS train {} valid {} ACC {}'.format(avg_loss, avg_vloss,v_acc))\n",
    "\n",
    "wandb.save(\"model_ViT_60K.pth\")\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efc84a6d-590d-41aa-a68f-1d64bbbc49df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60k ViT ==>  0.1135\n"
     ]
    }
   ],
   "source": [
    "print(\"60k ViT ==> \",v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fbcc67f4-7f2d-410a-bea5-e9fff013246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=2)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)  \n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  \n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x.mean(dim = 1) \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9770ed13-6f6e-4dbf-893d-d976aa6f0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4a0e43a2-b3e0-4f49-af7f-8eb7e4b1c167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "02e65812-ae84-4a48-8668-878427962dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:os8fnqtg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>vloss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.1028</td></tr><tr><td>train_loss</td><td>23.21601</td></tr><tr><td>vloss</td><td>2.32569</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TransformerModel_6K</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/os8fnqtg' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/os8fnqtg</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v5' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_174326-os8fnqtg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:os8fnqtg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc81322c34104703816a9cdc4819f612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112426111099517, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_175045-yruzai91</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/yruzai91' target=\"_blank\">TransformerModel_6K</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/yruzai91' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/yruzai91</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 64, 'epoch': 5, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"CV_A1_Q2\",name = \"TransformerModel_6K\")\n",
    "wandb.config.learning_rate = 0.001\n",
    "wandb.config.batch_size = 64\n",
    "wandb.config.epoch = 5\n",
    "wandb.config.optimizer = \"adam\"\n",
    "pprint(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "484c3b39-055e-464b-b766-a0d87464a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 6016 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "batch_size = wandb.config.batch_size\n",
    "learning_rate = wandb.config.learning_rate\n",
    "epochs = wandb.config.epoch\n",
    "\n",
    "num_training_samples = 6000\n",
    "# num_training_samples = 60000\n",
    "training_loader, validation_loader = data_get_load_num_samp(batch_size, num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd111aca-5bee-413f-aba2-7449a76c0ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srihari/miniconda3/envs/conda_cv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.948887436947924 valid 0.007090409817546606 ACC 0.8619\n",
      "EPOCH 2:\n",
      "LOSS train 0.4229620489034247 valid 0.006002545506507158 ACC 0.8814\n",
      "EPOCH 3:\n",
      "LOSS train 0.4263200173352627 valid 0.004800592842698097 ACC 0.9051\n",
      "EPOCH 4:\n",
      "LOSS train 0.3359704148420628 valid 0.0046090925229713324 ACC 0.9104\n",
      "EPOCH 5:\n",
      "LOSS train 0.34182175423236605 valid 0.005484303507581353 ACC 0.8973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▇█▆</td></tr><tr><td>train_loss</td><td>█▂▂▁▁</td></tr><tr><td>vloss</td><td>█▅▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.8973</td></tr><tr><td>train_loss</td><td>0.34182</td></tr><tr><td>vloss</td><td>0.00548</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TransformerModel_6K</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/yruzai91' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/yruzai91</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v5' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_175045-yruzai91/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Create an instance of the VisionTransformer model\n",
    "model = TransformerModel(input_dim = 28 * 28, hidden_dim = 256, output_dim = 10, num_layers = 2)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = build_optimizer(model, wandb.config.optimizer, wandb.config.learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch_number in range(wandb.config.epoch):  # Number of epochs\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "#######################\n",
    "# Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    running_loss =0\n",
    "    last_loss = 0\n",
    "    losses=[]\n",
    "    for i,data in enumerate(training_loader):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        optimizer.zero_grad()        \n",
    "        outputs=model(inputs)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss +=loss.item()\n",
    "        losses.append(loss.item())\n",
    "        if i%1000 == 999:\n",
    "            last_loss = running_loss/100\n",
    "            print(f\"{i+1}th batch => {last_loss}\")\n",
    "            running_loss = 0.\n",
    "    if last_loss==0:\n",
    "        avg_loss = np.mean(np.array(losses))\n",
    "    else:\n",
    "        avg_loss = last_loss\n",
    "################################\n",
    "\n",
    "    model.eval()\n",
    "    running_loss =0\n",
    "    last_loss = 0\n",
    "    correct = 0\n",
    "    test_loader = validation_loader\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(validation_loader):\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "            \n",
    "            outputs=model(inputs)\n",
    "            \n",
    "            loss = loss_fn(outputs,labels)\n",
    "            running_loss +=loss.item()\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    v_acc = correct/len(test_loader.dataset)\n",
    "    avg_vloss= running_loss/len(test_loader.dataset)\n",
    "############################\n",
    "    \n",
    "    wandb.log({\"train_loss\":avg_loss,\"vloss\":avg_vloss,\"accuracy\":v_acc})\n",
    "    \n",
    "    print('LOSS train {} valid {} ACC {}'.format(avg_loss, avg_vloss,v_acc))\n",
    "\n",
    "wandb.save(\"model_ViT_6k.pth\")\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03c5b26b-eea5-4aa1-a18d-016be32d62a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6k ViT ==>  0.8973\n"
     ]
    }
   ],
   "source": [
    "print(\"6k ViT ==> \",v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8138478b-6ff5-4105-9561-db165ba15089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ebcfc573341acb30115a5f6e57952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114276600023409, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/srihari/SEM6/CV/CV/CV_A2/wandb/run-20240308_175647-ozd4jtv9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/ozd4jtv9' target=\"_blank\">TransformerModel_60K</a></strong> to <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sriharib128/CV_A1_Q2' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/ozd4jtv9' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/ozd4jtv9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'batch_size': 64, 'epoch': 5, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"CV_A1_Q2\",name = \"TransformerModel_60K\")\n",
    "wandb.config.learning_rate = 0.001\n",
    "wandb.config.batch_size = 64\n",
    "wandb.config.epoch = 5\n",
    "wandb.config.optimizer = \"adam\"\n",
    "pprint(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b4cb457a-d360-49a1-b816-8b539d668bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60032 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "batch_size = wandb.config.batch_size\n",
    "learning_rate = wandb.config.learning_rate\n",
    "epochs = wandb.config.epoch\n",
    "\n",
    "# num_training_samples = 6000\n",
    "num_training_samples = 60000\n",
    "training_loader, validation_loader = data_get_load_num_samp(batch_size, num_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "20a391a8-0e8f-4cee-97d1-b325b3743d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srihari/miniconda3/envs/conda_cv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.4169465715188716 valid 0.0035603805648162963 ACC 0.929\n",
      "EPOCH 2:\n",
      "LOSS train 0.2101337081019971 valid 0.002652829633979127 ACC 0.9458\n",
      "EPOCH 3:\n",
      "LOSS train 0.1635349067980483 valid 0.002282949787774123 ACC 0.9552\n",
      "EPOCH 4:\n",
      "LOSS train 0.1377259057823386 valid 0.0024871663068421184 ACC 0.9503\n",
      "EPOCH 5:\n",
      "LOSS train 0.12256830568903926 valid 0.002051530849467963 ACC 0.9602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▇▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>vloss</td><td>█▄▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9602</td></tr><tr><td>train_loss</td><td>0.12257</td></tr><tr><td>vloss</td><td>0.00205</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TransformerModel_60K</strong> at: <a href='https://wandb.ai/sriharib128/CV_A1_Q2/runs/ozd4jtv9' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/runs/ozd4jtv9</a><br/> View job at <a href='https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v5' target=\"_blank\">https://wandb.ai/sriharib128/CV_A1_Q2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjUyMzcyNw==/version_details/v5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_175647-ozd4jtv9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Create an instance of the VisionTransformer model\n",
    "model = TransformerModel(input_dim = 28 * 28, hidden_dim = 256, output_dim = 10, num_layers = 2)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = build_optimizer(model, wandb.config.optimizer, wandb.config.learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch_number in range(wandb.config.epoch):  # Number of epochs\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "#######################\n",
    "# Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    running_loss =0\n",
    "    last_loss = 0\n",
    "    losses=[]\n",
    "    for i,data in enumerate(training_loader):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        optimizer.zero_grad()        \n",
    "        outputs=model(inputs)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss +=loss.item()\n",
    "        losses.append(loss.item())\n",
    "        if i%1000 == 999:\n",
    "            last_loss = running_loss/100\n",
    "            print(f\"{i+1}th batch => {last_loss}\")\n",
    "            running_loss = 0.\n",
    "    if last_loss==0:\n",
    "        avg_loss = np.mean(np.array(losses))\n",
    "    else:\n",
    "        avg_loss = last_loss\n",
    "################################\n",
    "\n",
    "    model.eval()\n",
    "    running_loss =0\n",
    "    last_loss = 0\n",
    "    correct = 0\n",
    "    test_loader = validation_loader\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(validation_loader):\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "            \n",
    "            outputs=model(inputs)\n",
    "            \n",
    "            loss = loss_fn(outputs,labels)\n",
    "            running_loss +=loss.item()\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    v_acc = correct/len(test_loader.dataset)\n",
    "    avg_vloss= running_loss/len(test_loader.dataset)\n",
    "############################\n",
    "    \n",
    "    wandb.log({\"train_loss\":avg_loss,\"vloss\":avg_vloss,\"accuracy\":v_acc})\n",
    "    \n",
    "    print('LOSS train {} valid {} ACC {}'.format(avg_loss, avg_vloss,v_acc))\n",
    "\n",
    "wandb.save(\"model_ViT_60k.pth\")\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5d3ff922-2ba9-401f-b2bb-59741b0b21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60k ViT ==>  0.9602\n"
     ]
    }
   ],
   "source": [
    "print(\"60k ViT ==> \",v_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab35655-c06d-414f-aaf6-600f947d7113",
   "metadata": {},
   "source": [
    "- **Performance Comparison: CNN vs. TransformerEncoder**\n",
    "  - **6K Images:**\n",
    "    - CNN: 94% Accuracy\n",
    "    - TransformerEncoder: 89% Accuracy\n",
    "    - The CNN outperformed the TransformerEncoder with 6K images, indicating that the CNN architecture might be more effective for less data.\n",
    "    - We can infer that Transformer model needs more data to train effectively\n",
    "\n",
    "  - **60K Images:**\n",
    "    - CNN: 98% Accuracy\n",
    "    - TransformerEncoder: 96% Accuracy\n",
    "    - While the CNN still achieved a slightly higher accuracy, the TransformerEncoder demonstrated a significant improvement from the 6K scenario. The gap between the two models decreased, suggesting that the TransformerEncoder benefits more from a larger dataset.\n",
    "    - Also the training time for Transformer architecture was faster compared to CNN architecture while both gave similar results\n",
    "    - Fine tuning the Transformer model might give better results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbd49e-4be3-4cb8-b673-6cf4ff07b653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
