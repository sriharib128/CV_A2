{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0648513-1383-4374-ad50-63910d69ceb4",
   "metadata": {},
   "source": [
    "# Q1: SIFT-BoVW-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fda7ea0-f3a0-4791-ba12-8dd1ac8a646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d7179-d457-4254-b5f5-560dc8417859",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device,torch.__version__,torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c12af-34e2-4da2-8935-bd6db096653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1bcfb-9786-455e-8641-aedc8d7b650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load MNIST dataset\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(mnist_train.data.numpy(), mnist_train.targets.numpy(), test_size=0.01, random_state=42)\n",
    "X_test, y_test = mnist_test.data.numpy(), mnist_test.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade04ea-1c29-443d-9ead-73af95c7d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random_integers = [np.random.randint(0, 50000) for _ in range(4)]\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 4))\n",
    "for i in range(4):\n",
    "    axes[i].imshow(X_train[random_integers[i]], cmap=\"gray\")\n",
    "    axes[i].set_title(f\"Label: {y_train[random_integers[i]]}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dca8e313-0fa0-42a8-97b2-ed563751ebba",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(all_descriptors),all_descriptors[0].shape => (464931, (128,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc5283-f828-4290-a9cd-ee15c470b9f1",
   "metadata": {},
   "source": [
    "## 1) SIFT detector and descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27737c06-781f-453a-99dc-c54a88dc7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptors = []\n",
    "descriptors_file = \"./q1_pickle_files/all_descriptors.pkl\"\n",
    "if os.path.exists(descriptors_file):\n",
    "    with open(descriptors_file,\"rb\") as f:\n",
    "        all_descriptors = pickle.load(f)\n",
    "else:\n",
    "    for i in range(len(X_train)):\n",
    "        keypoints, descriptors = cv2.SIFT_create().detectAndCompute(X_train[i], None)\n",
    "        if descriptors is not None:\n",
    "            all_descriptors.extend(descriptors)\n",
    "    with open(descriptors_file,\"wb\") as f:\n",
    "        pickle.dump(all_descriptors,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621dbf8-2e90-4602-adc4-46b1763263a7",
   "metadata": {},
   "source": [
    "### K-means clustering of descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed6482-6f3d-4ec7-b05c-d4da3eeef9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 100\n",
    "\n",
    "if os.path.exists(\"./q1_pickle_files/kmeans_model.pkl\"):\n",
    "    with open('./q1_pickle_files/kmeans_model.pkl', 'rb') as f:\n",
    "        kmeans = pickle.load(f)\n",
    "else:\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(np.array(all_descriptors))\n",
    "    with open('./q1_pickle_files/kmeans_model.pkl','wb') as f:\n",
    "        pickle.dump(kmeans,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98202d-87c3-4a1e-aeef-18d77dd5319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.shape,kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db134614-3e16-4365-9105-f555dfb53ea9",
   "metadata": {},
   "source": [
    "### Representing Images as Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af72c7-f425-410e-aec5-a062b4ed761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_histogram(image, kmeans,hyp=None):\n",
    "    if not hyp:\n",
    "        keypoints, descriptors =  hyp.detectAndCompute(image,None)    \n",
    "    else:\n",
    "        keypoints, descriptors =  cv2.SIFT_create().detectAndCompute(image,None)\n",
    "    if descriptors is not None:\n",
    "        words = kmeans.predict(descriptors)\n",
    "        histogram, _ = np.histogram(words, bins=range(len(kmeans.cluster_centers_)+1))\n",
    "        return histogram\n",
    "    else:\n",
    "        return np.zeros(len(kmeans.cluster_centers_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d55595-3177-42f3-ac6a-749a788019c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_train = './q1_pickle_files/X_train_bovw.pkl'\n",
    "pickle_file_test = './q1_pickle_files/X_test_bovw.pkl'\n",
    "\n",
    "if os.path.exists(pickle_file_train) and os.path.exists(pickle_file_test):\n",
    "    with open(pickle_file_train, 'rb') as f:\n",
    "        X_train_bovw = pickle.load(f)\n",
    "    with open(pickle_file_test, 'rb') as f:\n",
    "        X_test_bovw = pickle.load(f)\n",
    "else:\n",
    "    X_train_bovw = np.array([image_histogram(img, kmeans) for img in X_train])\n",
    "    X_test_bovw = np.array([image_histogram(img, kmeans) for img in X_test])\n",
    "\n",
    "    with open(pickle_file_train, 'wb') as f:\n",
    "        pickle.dump(X_train_bovw, f)\n",
    "    with open(pickle_file_test, 'wb') as f:\n",
    "        pickle.dump(X_test_bovw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcacfd-fc43-4cde-b477-0348d2c51259",
   "metadata": {},
   "source": [
    "### Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bd011-cc7d-4cc6-94b7-9b3b5c57857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./q1_pickle_files/svm_model.pkl\"):\n",
    "    with open('./q1_pickle_files/svm_model.pkl', 'rb') as f:\n",
    "        svm = pickle.load(f)\n",
    "else:\n",
    "    svm = SVC(kernel='linear',random_state=42)\n",
    "    svm.fit(X_train_bovw, y_train)\n",
    "    with open('./q1_pickle_files/svm_model.pkl', 'wb') as f:\n",
    "        pickle.dump(svm,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2faee-6bd4-4df9-83b5-401be41f74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test_bovw)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56151056-b482-4c0c-93e5-d1984a90b772",
   "metadata": {},
   "source": [
    "## 2) Changing no of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57420811-9c90-483e-be24-f5a500f13258",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [10,30,100,500,1000]\n",
    "accuracies = []\n",
    "accuracies_file = \"./q1_pickle_files/accuracies.pkl\"\n",
    "if os.path.exists(accuracies_file):\n",
    "    with open(accuracies_file,\"rb\") as f:\n",
    "        accuracies = pickle.load(f)\n",
    "else:\n",
    "    for num_clusters in clusters:\n",
    "        \n",
    "        ## kmeans_Clustering\n",
    "        kmeans_file =f\"./q1_pickle_files/kmeans_model_{num_clusters}.pkl\"\n",
    "        if os.path.exists(kmeans_file):\n",
    "            with open(kmeans_file, 'rb') as f:\n",
    "                kmeans = pickle.load(f)\n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "            kmeans.fit(np.array(all_descriptors))\n",
    "            with open(kmeans_file,'wb') as f:\n",
    "                pickle.dump(kmeans,f)\n",
    "    \n",
    "        ## Representing using bag of words\n",
    "        pickle_file_train = f'./q1_pickle_files/X_train_bovw_{num_clusters}.pkl'\n",
    "        pickle_file_test = f'./q1_pickle_files/X_test_bovw{num_clusters}.pkl'\n",
    "        \n",
    "        if os.path.exists(pickle_file_train) and os.path.exists(pickle_file_test):\n",
    "            with open(pickle_file_train, 'rb') as f:\n",
    "                X_train_bovw = pickle.load(f)\n",
    "            with open(pickle_file_test, 'rb') as f:\n",
    "                X_test_bovw = pickle.load(f)\n",
    "        else:\n",
    "            X_train_bovw = np.array([image_histogram(img, kmeans) for img in X_train])\n",
    "            X_test_bovw = np.array([image_histogram(img, kmeans) for img in X_test])\n",
    "    \n",
    "            # num_cores = 20  # Adjust this to the desired number of cores\n",
    "            \n",
    "            # with multiprocessing.Pool(num_cores) as pool:\n",
    "            #     X_train_bovw = np.array(pool.map(image_histogram, X_train, [kmeans] * len(X_train)))\n",
    "            #     X_test_bovw = np.array(pool.map(image_histogram, X_test, [kmeans] * len(X_test)))\n",
    "    \n",
    "            with open(pickle_file_train, 'wb') as f:\n",
    "                pickle.dump(X_train_bovw, f)\n",
    "            with open(pickle_file_test, 'wb') as f:\n",
    "                pickle.dump(X_test_bovw, f)\n",
    "    \n",
    "    \n",
    "        ## Training SVM Model\n",
    "        if os.path.exists(f\"./q1_pickle_files/svm_model_{num_clusters}.pkl\"):\n",
    "            with open(f'./q1_pickle_files/svm_model_{num_clusters}.pkl', 'rb') as f:\n",
    "                svm = pickle.load(f)\n",
    "        else:\n",
    "            svm = SVC(kernel='linear',random_state=42)\n",
    "            svm.fit(X_train_bovw, y_train)\n",
    "            with open(f'./q1_pickle_files/svm_model_{num_clusters}.pkl', 'wb') as f:\n",
    "                pickle.dump(svm,f)\n",
    "    \n",
    "        ## Storing Accuracies\n",
    "        print(num_clusters)\n",
    "        y_pred = svm.predict(X_test_bovw)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy_{num_clusters}:\", accuracy)\n",
    "        accuracies.append(accuracy)\n",
    "    with open(accuracies_file,\"wb\") as f:\n",
    "        pickle.dump(accuracies,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc827d9b-b53e-4807-a462-624cf3a3233d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2686efd-0511-4aba-9d53-319327775755",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clusters)):\n",
    "    print(clusters[i],\" ==> \",accuracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc05a2-92a6-4194-9522-50de5526ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(clusters,accuracies)\n",
    "ax.set_xlabel(\"Number of Clusters\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"No of clusters vs Accuracy Plot\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab36340-4222-44f1-a766-a809ccd8fb19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a2e8f73-9957-47f7-a1f9-c97ff57870ee",
   "metadata": {},
   "source": [
    "###### SIFT detector:\n",
    "1. n_octaves: Higher values might capture keypoints at more scales, potentially improving accuracy for objects at different sizes or orientations, but could also increase computation time.\n",
    "2. initial_sigma: Larger values could lead to more blurred features, affecting matching accuracy.\n",
    "3. threshold: More aggressive filtering (lower values) might remove valid keypoints, reducing accuracy, while less filtering might increase false positives.\n",
    "\n",
    "###### Linear SVM:\n",
    "1. C: Higher values correspond to stronger regularization, potentially preventing overfitting but also reducing model flexibility.\n",
    "2. loss: 'hinge' is the standard SVM loss, while 'squared_hinge' might be less sensitive to outliers but may have slower convergence.\n",
    "3. tol: Tighter tolerance (lower values) might require more iterations during training but could lead to more precise models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8b83c-702d-4022-8da3-d52d5310b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter ranges to explore\n",
    "sift_params = {\n",
    "    'nfeatures': [50, 100, 200, 300],\n",
    "    'nOctaveLayers': [1, 2, 3],\n",
    "    'contrastThreshold': [0.03, 0.04, 0.05],\n",
    "    'edgeThreshold': [10],  # Keep default value\n",
    "    'sigma': [1.4, 1.6, 1.8],\n",
    "    'enable_precise_upscale': [False]  # Keep default value\n",
    "}\n",
    "\n",
    "# Define hyperparameter ranges to explore\n",
    "svm_params = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'tol': [1e-4, 1e-5],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b8e46-a04f-4905-8a7a-6bf0da48cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_params_file=\"./q1_pickle_files/random_sift_params.pkl\"\n",
    "svm_params_file=\"./q1_pickle_files/randon_svm_params.pkl\"\n",
    "\n",
    "# Check if pickle files exist\n",
    "if not os.path.exists(sift_params_file):\n",
    "    # Create and save random_sift_params\n",
    "    random_sift_params = [{key: random.choice(value) for key, value in sift_params.items()} for _ in range(6)]\n",
    "    with open(sift_params_file, 'wb') as f:\n",
    "        pickle.dump(random_sift_params, f)\n",
    "    print(f\"{sift_params_file} created.\")\n",
    "else:\n",
    "    with open(sift_params_file, 'rb') as f:\n",
    "        random_sift_params = pickle.load(f)\n",
    "\n",
    "if not os.path.exists(svm_params_file):\n",
    "    # Create and save random_svm_params\n",
    "    random_svm_params = [{key: random.choice(value) for key, value in svm_params.items()} for _ in range(6)]\n",
    "    with open(svm_params_file, 'wb') as f:\n",
    "        pickle.dump(random_svm_params, f)\n",
    "    print(f\"{svm_params_file} created.\")\n",
    "else:\n",
    "    with open(svm_params_file, 'rb') as f:\n",
    "        random_svm_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e45bf-969b-4279-bc05-38a084ea0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_hyp=[]\n",
    "accuracies_hyp_file =\"./q1_pickle_files/accuracies_hyp.pkl\"\n",
    "\n",
    "if os.path.exists(accuracies_hyp_file):\n",
    "    with open(accuracies_hyp_file,\"rb\") as f:\n",
    "        accuracies_hyp = pickle.load(f)\n",
    "else:\n",
    "    for param_count in range(6):\n",
    "    \n",
    "        # calculating all descriptors\n",
    "        sift = cv2.SIFT_create(**random_sift_params[param_count])\n",
    "    \n",
    "        all_descriptors = []\n",
    "        descriptors_file = f\"./q1_pickle_files/all_descriptors_{param_count}.pkl\"\n",
    "        if os.path.exists(descriptors_file):\n",
    "            with open(descriptors_file,\"rb\") as f:\n",
    "                all_descriptors = pickle.load(f)\n",
    "        else:\n",
    "            for i in range(len(X_train)):\n",
    "                keypoints, descriptors = sift.detectAndCompute(X_train[i], None)\n",
    "                if descriptors is not None:\n",
    "                    all_descriptors.extend(descriptors)\n",
    "            with open(descriptors_file,\"wb\") as f:\n",
    "                pickle.dump(all_descriptors,f)\n",
    "    \n",
    "        # clustering using Kmeans\n",
    "        num_clusters = 100\n",
    "        \n",
    "        if os.path.exists(f\"./q1_pickle_files/kmeans_model_{param_count}.pkl\"):\n",
    "            with open(f'./q1_pickle_files/kmeans_model_{param_count}.pkl', 'rb') as f:\n",
    "                kmeans = pickle.load(f)\n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "            kmeans.fit(np.array(all_descriptors))\n",
    "            with open(f'./q1_pickle_files/kmeans_model_{param_count}.pkl','wb') as f:\n",
    "                pickle.dump(kmeans,f)\n",
    "    \n",
    "        #Representing images as histograms\n",
    "    \n",
    "        pickle_file_train = f'./q1_pickle_files/X_train_bovw_{param_count}.pkl'\n",
    "        pickle_file_test = f'./q1_pickle_files/X_test_bovw_{param_count}.pkl'\n",
    "        \n",
    "        if os.path.exists(pickle_file_train) and os.path.exists(pickle_file_test):\n",
    "            with open(pickle_file_train, 'rb') as f:\n",
    "                X_train_bovw = pickle.load(f)\n",
    "            with open(pickle_file_test, 'rb') as f:\n",
    "                X_test_bovw = pickle.load(f)\n",
    "        else:\n",
    "            X_train_bovw = np.array([image_histogram(img, kmeans,sift) for img in X_train])\n",
    "            X_test_bovw = np.array([image_histogram(img, kmeans,sift) for img in X_test])\n",
    "        \n",
    "            with open(pickle_file_train, 'wb') as f:\n",
    "                pickle.dump(X_train_bovw, f)\n",
    "            with open(pickle_file_test, 'wb') as f:\n",
    "                pickle.dump(X_test_bovw, f)\n",
    "    \n",
    "        # Linear SVM Model\n",
    "        if os.path.exists(f\"./q1_pickle_files/svm_model_{param_count}.pkl\"):\n",
    "            with open(f'./q1_pickle_files/svm_model_{param_count}.pkl', 'rb') as f:\n",
    "                svm = pickle.load(f)\n",
    "        else:\n",
    "            svm = SVC(kernel='linear',random_state=42)\n",
    "            svm.fit(X_train_bovw, y_train)\n",
    "            with open(f'./q1_pickle_files/svm_model_{param_count}.pkl', 'wb') as f:\n",
    "                pickle.dump(svm,f)\n",
    "        \n",
    "        y_pred = svm.predict(X_test_bovw)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"SIFT params: {random_sift_params[param_count]}, SVM params: {random_svm_params[param_count]}, Accuracy: {accuracy}\")\n",
    "        accuracies_hyp.append(accuracy)\n",
    "    with open(accuracies_hyp_file,\"wb\") as f:\n",
    "        pickle.dump(accuracies_hyp,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21427188-0438-4cae-8ab4-5987fe88b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca061d-8865-4ac5-a2ab-6362f31b154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_count in range(6):\n",
    "    print(f\"SIFT params: {random_sift_params[param_count]}, SVM params: {random_svm_params[param_count]}, Accuracy: {accuracy}\")\n",
    "    print(accuracies_hyp[param_count])\n",
    "    print(\"=\"*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc0bcd-8dba-4fe5-9d07-64871e060a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe7a07-e654-48d8-802c-f3169a702525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
